{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding_RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POnIAIUEfEV0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, PackedSequence\n",
        "from torch import nn\n",
        "\n",
        "from torch import Tensor, dot, matmul\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Example**"
      ],
      "metadata": {
        "id": "tGyELfk0fTwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq = torch.FloatTensor([[3, 4, 5]])  \n",
        "print(seq)\n",
        "print(seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eevmstGIfWmq",
        "outputId": "91f6494f-9f39-4a87-c1cd-8aa15b516814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 4., 5.]])\n",
            "torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a basic RNN layer\n",
        "\n",
        "rnn = nn.RNN(input_size=1, hidden_size=1, num_layers=1, bias = False, batch_first=True)\n",
        "\n",
        "# RNN expects input sequences to be in a particular format. By setting batch_first = True, \n",
        "# we set the input data format to be 'batch size, sequence length, # input features'"
      ],
      "metadata": {
        "id": "o68i5gI_fXWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = seq.unsqueeze(2)\n",
        "print(seq.shape)\n",
        "print(seq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNlJVFGSfXT0",
        "outputId": "f8650de5-8e73-457a-9b3c-03f24219c10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 1])\n",
            "tensor([[[3.],\n",
            "         [4.],\n",
            "         [5.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the correct input format, we can now pass the input to the RNN layer. The RNN layer provides 2 outputs\n",
        "\n",
        "1.All hidden states associated with a sequence, for all sequences in the batch\n",
        "\n",
        "2.Just the very last hidden state for a sequence, for all sequences in the batch"
      ],
      "metadata": {
        "id": "CDcdpqp9g7JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_all, out_last = rnn(seq)"
      ],
      "metadata": {
        "id": "WuSjjIBufXRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Out all shape : {out_all.shape}\")\n",
        "\n",
        "print(f\"Out last shape : {out_last.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P69esnuQfXOQ",
        "outputId": "f1cb871c-9aea-46bc-e1fb-8a9088b99c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out all shape : torch.Size([1, 3, 1])\n",
            "Out last shape : torch.Size([1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 ways that we can acess the weights of the RNN layer.\n",
        "\n",
        "1.Accessing individual parameters using their names weight_hh_10, weight_1h_10 and so on.\n",
        "\n",
        "2.Using the state_dict() parameter to access all weights"
      ],
      "metadata": {
        "id": "-Dz0dAhdyqQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.weight_hh_l0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE3supUUfXLW",
        "outputId": "b9c8f5dc-aa08-442e-f7bc-e934f2684461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.8218]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.weight_ih_l0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCRn-v8szAXJ",
        "outputId": "83796257-8413-417e-e23d-f84ae84126c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.8769]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZBIQoe9zGLj",
        "outputId": "61a09c4f-250d-4791-faa8-b4715f96a83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih_l0', tensor([[-0.8769]])),\n",
              "             ('weight_hh_l0', tensor([[-0.8218]]))])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the output\n",
        "RNN layers essentially take in a sequence and compute outputs for each time point in the input sequence. The weights that are used for computation remain the same for all time points.\n",
        "\n",
        "The basic equation governing the computation is given by : tanh(wihXt + bih + whh h(t-1) + bhh)\n",
        "\n",
        "where  represents the hidden state at time t"
      ],
      "metadata": {
        "id": "PqMvaGvdz5Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output states computed by the RNN layer\n",
        "out_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGgWbNZGKlhl",
        "outputId": "d6bdfe82-00d7-4518-d9bf-ec81fb00136a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9897],\n",
              "         [-0.9909],\n",
              "         [-0.9984]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 1\n",
        "\n",
        "Note. Since this is the very first state (time = 1) and we dont have a hidden state preceding it, we assumne it be zero. Therefore, h0 is taken to be 0."
      ],
      "metadata": {
        "id": "6KWHiA0YKqcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wih = rnn.weight_ih_l0\n",
        "whh = rnn.weight_hh_l0\n",
        "\n",
        "x = seq[0][0] # The first input feature of the first sequence\n",
        "\n",
        "# Computing thw hidden state for time = 1\n",
        "h1 = torch.tanh(Tensor(x*wih + whh*0))  \n",
        "h1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjBeknDbKkwJ",
        "outputId": "c95422c5-56e8-4fbe-a01d-56663be8b258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9897]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 2"
      ],
      "metadata": {
        "id": "sXZlLn6qz4ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = seq[0][1] # The second input feature of the first sequence\n",
        "\n",
        "h2 = torch.tanh(Tensor(x*wih + whh*h1))  \n",
        "h2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbr-rltLK4mB",
        "outputId": "eaa4115d-5332-432a-f98b-586b6d508093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9909]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 3"
      ],
      "metadata": {
        "id": "lUr0U0WrLDzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = seq[0][2] # The third and last input feature of the first sequence\n",
        "\n",
        "h3 = torch.tanh(Tensor(x*wih + whh*h2))  \n",
        "h3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iV7zuikLDjD",
        "outputId": "33d1904c-fb7c-4aaa-dae8-61fc5c5d3cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9984]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that :\n",
        "\n",
        "1.RNN does a very basic computation repeatedly on all features of the given sequence\n",
        "\n",
        "2.The output at a particular time stamp depends on the outputs at a previous time stamp"
      ],
      "metadata": {
        "id": "jewuSiEaLLKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding more features\n",
        "\n",
        "We increase the complexity of the RNN computation by increasing the number of features at each sequence time stamp. Previously, each time stamp was represented by a single value. Now, we expand that to be represented by a feature vector"
      ],
      "metadata": {
        "id": "dONeuqMEL33l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq = torch.Tensor([[1,1,1],[1,2,1],[2,3,1], [1,3,1]])\n",
        "print(seq.shape)\n",
        "print(seq)\n",
        "seq = seq.unsqueeze(0)\n",
        "print(seq.shape)\n",
        "print(seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5T4kVMbK5In",
        "outputId": "6647aa56-7e72-4635-832c-1d5dea432014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 2., 1.],\n",
            "        [2., 3., 1.],\n",
            "        [1., 3., 1.]])\n",
            "torch.Size([1, 4, 3])\n",
            "tensor([[[1., 1., 1.],\n",
            "         [1., 2., 1.],\n",
            "         [2., 3., 1.],\n",
            "         [1., 3., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The seq variable represents a sequence of length 4, where each element (time-stamp) is represented by a feature vector of length 3.\n",
        "\n",
        "We next define a RNN layer where we set input_size to be 3. This time, we also set bias to be True, so that we include a bias term in our calculations"
      ],
      "metadata": {
        "id": "eIl7bdsMMmEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a basic RNN layer\n",
        "\n",
        "rnn = nn.RNN(input_size=3, hidden_size=1, num_layers=1, bias=True, batch_first=True)"
      ],
      "metadata": {
        "id": "zzK6dtCxK5Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_all, out_last = rnn(seq)\n",
        "\n",
        "print(f\"Out all shape : {out_all.shape}\")\n",
        "\n",
        "print(f\"Out last shape : {out_last.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGjHQDQAK5DX",
        "outputId": "5aa581f7-0ada-49b7-f1cf-e923eee55f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out all shape : torch.Size([1, 4, 1])\n",
            "Out last shape : torch.Size([1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing outputs"
      ],
      "metadata": {
        "id": "HSGLSg_0NXGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyMi5YiiNYlP",
        "outputId": "d2e54f9b-aa3f-43b7-a8e5-f6e0baa0f680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.1408],\n",
              "         [0.8286],\n",
              "         [0.9486],\n",
              "         [0.9908]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 1\n",
        "\n",
        "A minor modification compared to the previous code is that we will be using dot multiplication to multiply x with Wih and h(t-1) with whh ."
      ],
      "metadata": {
        "id": "0O0acx1eQhSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wih = rnn.weight_ih_l0.squeeze(0)\n",
        "whh = rnn.weight_hh_l0.squeeze(0)\n",
        "\n",
        "bih = rnn.bias_ih_l0\n",
        "bhh = rnn.bias_hh_l0\n",
        "\n",
        "x = seq[0][0] # The first input feature of the first sequence\n",
        "\n",
        "# Computing thw hidden state for time = 1\n",
        "h1 = torch.tanh(Tensor(dot(x,wih) + bih  + dot(whh,Tensor([0.0])) + bhh))  \n",
        "h1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FppJHXN0QeH4",
        "outputId": "25d2a259-d239-44bb-b9db-6bce4931944d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1408], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 2"
      ],
      "metadata": {
        "id": "R3bmL3c-Sy5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = seq[0][1] # The first input feature of the first sequence\n",
        "\n",
        "# Computing thw hidden state for time = 1\n",
        "h2 = torch.tanh(Tensor(dot(x,wih) + bih  + dot(h1,whh) + bhh))  \n",
        "h2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AADaynaSz7R",
        "outputId": "dca3ed1c-d048-4954-fa79-3046c4faca19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8286], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing all states\n",
        "\n",
        "We automate the manual computation of hidden states to verify our computation matches with the RNN layer output"
      ],
      "metadata": {
        "id": "_NQkL99ES_4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "\n",
        "h_previous = Tensor([0.0])\n",
        "\n",
        "for i in range(seq.shape[1]):\n",
        "\n",
        "    if i==0:\n",
        "        x = seq[0][i]\n",
        "        h_current = torch.tanh(Tensor(dot(x,wih) + bih + dot(h_previous, whh) + bhh))\n",
        "        h_previous = h_current\n",
        "        output.append(h_current.detach().numpy())\n",
        "\n",
        "    else:\n",
        "        x = seq[0][i]\n",
        "        h_current = torch.tanh(Tensor(dot(x,wih) + bih + dot(h_previous, whh) + bhh))\n",
        "        h_previous = h_current\n",
        "        output.append(h_current.detach().numpy())\n"
      ],
      "metadata": {
        "id": "zp2xf65gS8YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiVNeT4ugNbm",
        "outputId": "fda92d09-5d1d-4577-c9bd-ba9e7b071088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.14078327], dtype=float32),\n",
              " array([0.82855445], dtype=float32),\n",
              " array([0.94859374], dtype=float32),\n",
              " array([0.9908491], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Increasing Hidden Size**\n",
        "\n",
        "Hidden size is number of features of the hidden state for RNN.So if you increase hidden size then you compute bigger feature as hidden state output.\n",
        "\n",
        "Till now, we had hidden_size parameter fixed at 1. We increase this value and see how it affects the RNN computation"
      ],
      "metadata": {
        "id": "Ub-33PT5hpbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the RNN layer\n",
        "rnn= nn.RNN(input_size=3, hidden_size=2, num_layers = 1, bias = True, batch_first=True)"
      ],
      "metadata": {
        "id": "B_X8z-SwgTZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_all, out_last = rnn(seq)\n",
        "\n",
        "print(f\"Out all shape : {out_all.shape}\")\n",
        "\n",
        "print(f\"Out last shape : {out_last.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ey3sdziBFZ",
        "outputId": "12d957f2-c5aa-413f-ee8f-33ed0dbb606b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out all shape : torch.Size([1, 4, 2])\n",
            "Out last shape : torch.Size([1, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the output shape that the size of the hidden states has increased to 2, corresponding to the increase in the hidden_size parameter to 2"
      ],
      "metadata": {
        "id": "_F_ok9rGiS52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FW35k8XiBAg",
        "outputId": "26f378b7-e21a-4246-f932-5807a553f341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih_l0', tensor([[ 0.5886, -0.0840,  0.1099],\n",
              "                      [-0.1125,  0.0505, -0.1764]])),\n",
              "             ('weight_hh_l0', tensor([[0.1692, 0.4006],\n",
              "                      [0.4108, 0.7006]])),\n",
              "             ('bias_ih_l0', tensor([0.5332, 0.4121])),\n",
              "             ('bias_hh_l0', tensor([-0.5042, -0.1715]))])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, the RNN layer weight shapes have also changed in response to the new hidden_size parameter value"
      ],
      "metadata": {
        "id": "lso1BE3IiaXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing outputs\n",
        "\n",
        "On increasing the hidden_size parameter to 2, we are essentially increase the size of the hidden states computed for each time-stamp. This essentially allows the hidden states to be more expressive and store more information."
      ],
      "metadata": {
        "id": "Ah_v0_nwiccV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuiXxjx8iA9y",
        "outputId": "d2dd6f22-a3ef-46ff-8a6a-c82e72e1cff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5673, 0.0021],\n",
              "         [0.5759, 0.2795],\n",
              "         [0.8547, 0.3994],\n",
              "         [0.6527, 0.6255]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 1"
      ],
      "metadata": {
        "id": "TngPDNf7iqRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wih = rnn.weight_ih_l0\n",
        "whh = rnn.weight_hh_l0\n",
        "\n",
        "bih = rnn.bias_ih_l0\n",
        "bhh = rnn.bias_hh_l0\n",
        "\n",
        "x = seq[0][0] # The first input feature of the first sequence\n",
        "\n",
        "# Computing thw hidden state for time = 1\n",
        "h1 = torch.tanh(Tensor(matmul(x,wih.T) + bih  + matmul( torch.zeros([1,2]) , whh.T ) + bhh))  \n",
        "h1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqj04qcGiA69",
        "outputId": "0d5f34a8-3b60-48f8-e117-7a01a6903b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5673, 0.0021]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing for all states"
      ],
      "metadata": {
        "id": "7-aKwl4TjCzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "\n",
        "h_previous = torch.zeros([1,2])  # Since the hidden_size parameter is 2, all hidden states will have a shape of [1,2]\n",
        "\n",
        "for i in range(seq.shape[1]):\n",
        "\n",
        "  x = seq[0][i]\n",
        "  h_current = torch.tanh(Tensor(matmul(x,wih.T) + bih  + matmul(h_previous,whh.T) + bhh))\n",
        "  h_previous = h_current\n",
        "  output.append(h_current)"
      ],
      "metadata": {
        "id": "VqWEKIPRjBdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fryvuA6iA4W",
        "outputId": "10c50f88-6371-4e7d-b8ed-93d6a63ef114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.5673, 0.0021]], grad_fn=<TanhBackward0>),\n",
              " tensor([[0.5759, 0.2795]], grad_fn=<TanhBackward0>),\n",
              " tensor([[0.8547, 0.3994]], grad_fn=<TanhBackward0>),\n",
              " tensor([[0.6527, 0.6255]], grad_fn=<TanhBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Bi-Directional RNN"
      ],
      "metadata": {
        "id": "wxhFWMDSjMZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the RNN layer\n",
        "rnn= nn.RNN(input_size=3, hidden_size=2, num_layers = 1, bias = True, batch_first=True, bidirectional=True)"
      ],
      "metadata": {
        "id": "Z8BF-4QZp4rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_all, out_last = rnn(seq)\n",
        "\n",
        "print(f\"Out all shape : {out_all.shape}\")\n",
        "\n",
        "print(f\"Out last shape : {out_last.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ5EzUEep4o4",
        "outputId": "34995fb1-bd80-46e5-8724-a57cfde69b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out all shape : torch.Size([1, 4, 4])\n",
            "Out last shape : torch.Size([2, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhtqKICep4mf",
        "outputId": "c09d7c98-f016-4c71-d9fd-21335ee42698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6201, -0.5690, -0.8503,  0.3732],\n",
              "         [ 0.7594, -0.9050, -0.9095,  0.6461],\n",
              "         [ 0.4136, -0.9911, -0.9002,  0.9371],\n",
              "         [ 0.6942, -0.9752, -0.9584,  0.9163]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_last"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJrPkA4Kp4jy",
        "outputId": "c1c59d32-da80-4c52-ec86-9a186a114904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6942, -0.9752]],\n",
              "\n",
              "        [[-0.8503,  0.3732]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR05Xj22p4g1",
        "outputId": "79d9c97b-fadf-4932-cc48-a358bad608a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih_l0', tensor([[-0.6735,  0.2324,  0.5187],\n",
              "                      [-0.5421, -0.4331,  0.1564]])),\n",
              "             ('weight_hh_l0', tensor([[ 0.5985,  0.5866],\n",
              "                      [-0.0808,  0.6500]])),\n",
              "             ('bias_ih_l0', tensor([ 0.5015, -0.3184])),\n",
              "             ('bias_hh_l0', tensor([0.1460, 0.4912])),\n",
              "             ('weight_ih_l0_reverse', tensor([[ 0.4697, -0.3869, -0.4899],\n",
              "                      [ 0.4505,  0.4845, -0.3718]])),\n",
              "             ('weight_hh_l0_reverse', tensor([[ 0.3995,  0.3990],\n",
              "                      [-0.0386, -0.3703]])),\n",
              "             ('bias_ih_l0_reverse', tensor([-0.3801, -0.4178])),\n",
              "             ('bias_hh_l0_reverse', tensor([-0.3645,  0.4508]))])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing outputs - Forward Direction\n",
        "\n",
        "For a bidirectional RNN layer with a hidden layer size of 2 and an input sequence of length 4, we get an output of size 4x4.\n",
        "\n",
        "In the output, each row essentially captures the hidden state corresponding to a given time-stamp. In the previous example, each time stamp was represented by a vector of length 2 (because hidden_size = 2). Now, since its bidirectional, each hidden state is represented by a vector of length 4 ( 2 + 2)\n",
        "\n",
        "For each timestamp, the first 2 values correspond to the forward run of the RNN and the last 2 values correspond to the backward run of the RNN."
      ],
      "metadata": {
        "id": "exXwWo5C1iRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hidden State 1 - Forward Direction"
      ],
      "metadata": {
        "id": "vczki3UJ1vAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wih = rnn.weight_ih_l0\n",
        "whh = rnn.weight_hh_l0\n",
        "\n",
        "bih = rnn.bias_ih_l0\n",
        "bhh = rnn.bias_hh_l0\n",
        "\n",
        "# We represent all reverse weights using a '_' suffix\n",
        "wih_ = rnn.weight_ih_l0_reverse\n",
        "whh_ = rnn.weight_hh_l0_reverse\n",
        "\n",
        "bih_ = rnn.bias_ih_l0_reverse\n",
        "bhh_ = rnn.bias_hh_l0_reverse\n",
        "\n",
        "x = seq[0][0] # The first input feature of the first sequence\n",
        "\n",
        "# Computing thw hidden state for time = 1\n",
        "h1 = torch.tanh(Tensor(matmul(x,wih.T) + bih  + matmul( torch.zeros([1,2]) , whh.T ) + bhh))  \n",
        "h1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI_wWvsgp4eX",
        "outputId": "d1e55668-187c-474d-849b-b4fee2f61edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6201, -0.5690]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing all states - Forward Direction"
      ],
      "metadata": {
        "id": "-QH65OFV1212"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "\n",
        "h_previous = torch.zeros([1,2])  # Since the hidden_size parameter is 2, all hidden states will have a shape of [1,2]\n",
        "\n",
        "for i in range(seq.shape[1]):\n",
        "\n",
        "  x = seq[0][i]\n",
        "  h_current = torch.tanh(Tensor(matmul(x,wih.T) + bih  + matmul(h_previous,whh.T) + bhh))\n",
        "  h_previous = h_current\n",
        "  output.append(h_current)\n",
        "\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CP7IJJTp4be",
        "outputId": "538d3cb8-6ea5-45e0-cd2b-2627de3a356b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.6201, -0.5690]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.7594, -0.9050]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.4136, -0.9911]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.6942, -0.9752]], grad_fn=<TanhBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this stage, we can compare the computed hidden states with the RNN layer output out_all. We can observe that computed states match to the first 2 elements of all the RNN layer outputs"
      ],
      "metadata": {
        "id": "EHhGSckT1-ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_all[:,:,:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFDaA_HN17ch",
        "outputId": "f78ca06a-29b0-4d8e-a2b7-8c6c51f84aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6201, -0.5690],\n",
              "         [ 0.7594, -0.9050],\n",
              "         [ 0.4136, -0.9911],\n",
              "         [ 0.6942, -0.9752]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing Outputs - Backward Direction\n",
        "\n",
        "Hidden State 1 - Backward direction"
      ],
      "metadata": {
        "id": "rhuG0rys2DYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = seq[0][-1] # The very last element of the sequence is now treated as the first element in the backward run\n",
        "\n",
        "# Computing thw hidden state for time = 4\n",
        "h4_ = torch.tanh(Tensor(matmul(x,wih_.T) + bih_  + matmul( torch.zeros([1,2]) , whh_.T ) + bhh_))  \n",
        "h4_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77HRMRVD2GSB",
        "outputId": "ec135d93-8341-4bbc-c803-2fb8b9bba187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9584,  0.9163]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 2 - Backward direction"
      ],
      "metadata": {
        "id": "X3lqeQQu2LGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = seq[0][-2] \n",
        "\n",
        "# Computing thw hidden state for time = 3\n",
        "h3_ = torch.tanh(Tensor(matmul(x,wih_.T) + bih_  + matmul( h4_ , whh_.T ) + bhh_))  \n",
        "h3_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJOcrZf92HHY",
        "outputId": "12a48537-6c84-4175-fb20-7a9d4b258440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9002,  0.9371]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 3 - Backward direction"
      ],
      "metadata": {
        "id": "eYL77IwA2Pi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = seq[0][-3] \n",
        "\n",
        "# Computing thw hidden state for time = 3\n",
        "h2_ = torch.tanh(Tensor(matmul(x,wih_.T) + bih_  + matmul( h3_ , whh_.T ) + bhh_))  \n",
        "h2_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E51VVCaq2HEo",
        "outputId": "2feec897-9ede-4e6b-ff80-6ae76d438f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9095,  0.6461]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden State 4 - Backward direction"
      ],
      "metadata": {
        "id": "0FF1gBCD2Sr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = seq[0][-4] \n",
        "\n",
        "# Computing thw hidden state for time = 3\n",
        "h1_ = torch.tanh(Tensor(matmul(x,wih_.T) + bih_  + matmul( h2_ , whh_.T ) + bhh_))  \n",
        "h1_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NozL4dZ2HCP",
        "outputId": "c3ad017f-3a7f-4400-9478-78c9662e740a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8503,  0.3732]], grad_fn=<TanhBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_ = [h1_,h2_,h3_,h4_]\n",
        "output_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdNU-JgD2G_m",
        "outputId": "62045fbc-ac15-445c-d280-3297ca739442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.8503,  0.3732]], grad_fn=<TanhBackward0>),\n",
              " tensor([[-0.9095,  0.6461]], grad_fn=<TanhBackward0>),\n",
              " tensor([[-0.9002,  0.9371]], grad_fn=<TanhBackward0>),\n",
              " tensor([[-0.9584,  0.9163]], grad_fn=<TanhBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_all[:,:,2:]   #Checking only the 2nd half of the RNN layer output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34KTHulf2bo8",
        "outputId": "7a46dee2-2dd7-4e38-f0c9-498ca3929469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8503,  0.3732],\n",
              "         [-0.9095,  0.6461],\n",
              "         [-0.9002,  0.9371],\n",
              "         [-0.9584,  0.9163]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final RNN layer output is the concatentation of hidden states from both the forward and backward runs. On doing so, we can compare our manually computed results with the RNN layer output"
      ],
      "metadata": {
        "id": "nWwL0REq2fJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fullOutput = [ torch.cat( (output[i], output_[i]),1)  for i in range(4) ]\n",
        "fullOutput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s443gGvg2dAZ",
        "outputId": "ebac656f-0408-4788-fd11-e15fa8f4cce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.6201, -0.5690, -0.8503,  0.3732]], grad_fn=<CatBackward0>),\n",
              " tensor([[ 0.7594, -0.9050, -0.9095,  0.6461]], grad_fn=<CatBackward0>),\n",
              " tensor([[ 0.4136, -0.9911, -0.9002,  0.9371]], grad_fn=<CatBackward0>),\n",
              " tensor([[ 0.6942, -0.9752, -0.9584,  0.9163]], grad_fn=<CatBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLyUJmsu2lhs",
        "outputId": "2e8dd2d6-e37a-4ad3-dd26-5b29597431a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6201, -0.5690, -0.8503,  0.3732],\n",
              "         [ 0.7594, -0.9050, -0.9095,  0.6461],\n",
              "         [ 0.4136, -0.9911, -0.9002,  0.9371],\n",
              "         [ 0.6942, -0.9752, -0.9584,  0.9163]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Stacked RNNs\n",
        "\n",
        "With Stacked RNNs, we explore the num_layers parameter of the RNN module. Stacked RNNs can be thought of individual RNN modules stacked together, with the output of one module acting as input to the next RNN module.\n",
        "\n"
      ],
      "metadata": {
        "id": "krCWGSJr2ogk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the RNN layer\n",
        "rnn= nn.RNN(input_size=3, hidden_size=3, num_layers = 2, bias = True, batch_first=True, bidirectional=False)"
      ],
      "metadata": {
        "id": "7yN1yCP12c9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_all, out_last = rnn(seq)\n",
        "\n",
        "print(f\"Out all shape : {out_all.shape}\")\n",
        "\n",
        "print(f\"Out last shape : {out_last.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE8jFPvb2czp",
        "outputId": "abe41ada-b64e-4b2d-d7b7-07c90f2ef340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out all shape : torch.Size([1, 4, 3])\n",
            "Out last shape : torch.Size([2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95cxFvaW2_ov",
        "outputId": "c260791b-7754-4179-dfbd-445826bae0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7045, -0.6622,  0.5480],\n",
              "         [ 0.6306, -0.5797,  0.3353],\n",
              "         [ 0.7372, -0.7367,  0.2066],\n",
              "         [ 0.7282, -0.7595,  0.2329]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_last"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJkXIuCH2_mg",
        "outputId": "5462b0ac-bc85-4743-876d-7d5caa73c2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7242, -0.8361,  0.7038]],\n",
              "\n",
              "        [[ 0.7282, -0.7595,  0.2329]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeSbRKt72_jf",
        "outputId": "db69ecd6-ca8d-4547-e9fb-05652677ccbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_ih_l0', tensor([[-0.0067,  0.5169, -0.4285],\n",
              "                      [ 0.4447, -0.5474,  0.3089],\n",
              "                      [-0.1507,  0.2443,  0.1886]])),\n",
              "             ('weight_hh_l0', tensor([[-0.1682, -0.2060, -0.0155],\n",
              "                      [-0.2151, -0.5301, -0.4871],\n",
              "                      [-0.4436, -0.2902, -0.5667]])),\n",
              "             ('bias_ih_l0', tensor([-0.0591, -0.4937,  0.2946])),\n",
              "             ('bias_hh_l0', tensor([-0.1003,  0.4496,  0.4387])),\n",
              "             ('weight_ih_l1', tensor([[ 0.2131,  0.1153,  0.4454],\n",
              "                      [-0.3610,  0.0018, -0.3609],\n",
              "                      [-0.4575,  0.0097, -0.0236]])),\n",
              "             ('weight_hh_l1', tensor([[ 0.0889, -0.0294, -0.3185],\n",
              "                      [ 0.1371,  0.1975,  0.5522],\n",
              "                      [ 0.3690,  0.3262, -0.1692]])),\n",
              "             ('bias_ih_l1', tensor([ 0.1758, -0.5126,  0.3801])),\n",
              "             ('bias_hh_l1', tensor([ 0.3563, -0.0351,  0.2165]))])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing Outputs - Layer 1"
      ],
      "metadata": {
        "id": "ykOShJgN3HMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the weights for RNN Layer 1\n",
        "wih_10 = rnn.weight_ih_l0\n",
        "whh_10 = rnn.weight_hh_l0\n",
        "\n",
        "bih_10 = rnn.bias_ih_l0\n",
        "bhh_10 = rnn.bias_hh_l0\n",
        "\n",
        "output_1 = []\n",
        "\n",
        "h_previous = torch.zeros([1,3])  # Since the hidden_size parameter is 3, all hidden states will have a shape of [1,3]\n",
        "\n",
        "for i in range(seq.shape[1]):\n",
        "\n",
        "  x = seq[0][i]\n",
        "  h_current = torch.tanh(Tensor(matmul(x,wih_10.T) + bih_10  + matmul(h_previous,whh_10.T) + bhh_10))\n",
        "  h_previous = h_current\n",
        "  output_1.append(h_current)\n",
        "\n",
        "output_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMjrYewc2_gs",
        "outputId": "864c45cf-26ac-42d3-f084-ba0c76a804d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.0775,  0.1607,  0.7680]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.3862, -0.6794,  0.6708]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.7674, -0.4912,  0.7612]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.7242, -0.8361,  0.7038]], grad_fn=<TanhBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing Outputs - Layer 2"
      ],
      "metadata": {
        "id": "Idl2oYxQ3N1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the weights for RNN Layer 1\n",
        "wih_11 = rnn.weight_ih_l1\n",
        "whh_11 = rnn.weight_hh_l1\n",
        "\n",
        "bih_11 = rnn.bias_ih_l1\n",
        "bhh_11 = rnn.bias_hh_l1\n",
        "\n",
        "output_2 = []\n",
        "\n",
        "h_previous = torch.zeros([1,3]) # Since the hidden_size parameter is 2, all hidden states will have a shape of [1,2]\n",
        "\n",
        "for i in range(seq.shape[1]):\n",
        "  \n",
        "  x = seq[0][i]\n",
        "  h_current = torch.tanh(Tensor(matmul(output_1[i],wih_11.T) + bih_11  + matmul(h_previous,whh_11.T) + bhh_11))\n",
        "  h_previous = h_current\n",
        "  output_2.append(h_current)\n",
        "\n",
        "output_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pooDl1A22_eH",
        "outputId": "3bb3a2da-6b36-43d8-a98c-946ef44ae2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.7045, -0.6622,  0.5480]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.6306, -0.5797,  0.3353]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.7372, -0.7367,  0.2066]], grad_fn=<TanhBackward0>),\n",
              " tensor([[ 0.7282, -0.7595,  0.2329]], grad_fn=<TanhBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2xosRB23Waf",
        "outputId": "057b10da-be33-49bf-88d9-274e81a4f091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7045, -0.6622,  0.5480],\n",
              "         [ 0.6306, -0.5797,  0.3353],\n",
              "         [ 0.7372, -0.7367,  0.2066],\n",
              "         [ 0.7282, -0.7595,  0.2329]]], grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_last"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmtomu1s2_bv",
        "outputId": "0a428d6f-451e-41ee-bb8d-aa0c4548372c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7242, -0.8361,  0.7038]],\n",
              "\n",
              "        [[ 0.7282, -0.7595,  0.2329]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "agGaGKz22_Yq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}